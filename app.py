import streamlit as st
from openai import OpenAI
import numpy as np
import PyPDF2
import os

# PDFèª­ã¿è¾¼ã¿ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª(ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«)
try:
    import pdfplumber
    HAS_PDFPLUMBER = True
except ImportError:
    HAS_PDFPLUMBER = False

try:
    import fitz  # PyMuPDF
    HAS_PYMUPDF = True
except ImportError:
    HAS_PYMUPDF = False

# OpenAI APIã®è¨­å®š
# Streamlit Cloudç”¨ã¨ãƒ­ãƒ¼ã‚«ãƒ«ç”¨ã®ä¸¡æ–¹ã«å¯¾å¿œ
try:
    # Streamlit Cloudã®å ´åˆ
    api_key = st.secrets["OPENAI_API_KEY"]
except (FileNotFoundError, KeyError):
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ
    from dotenv import load_dotenv
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("âŒ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.info("""
    **Streamlit Cloudã®å ´åˆ:**
    Settings â†’ Secrets ã§ä»¥ä¸‹ã‚’è¨­å®šã—ã¦ãã ã•ã„:
```
    OPENAI_API_KEY = "your_key_here"
```
    
    **ãƒ­ãƒ¼ã‚«ãƒ«ã®å ´åˆ:**
    .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„:
```
    OPENAI_API_KEY=your_key_here
```
    """)
    st.stop()

client = OpenAI(api_key=api_key)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¢ãƒ³ãƒˆãƒ‹ã‚ªçŒªæœ¨FAQãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
    page_icon="ğŸ’ª",
    layout="wide"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-title {
        font-size: 42px;
        font-weight: bold;
        text-align: center;
        color: #FF6B6B;
        margin-bottom: 10px;
    }
    .sub-title {
        font-size: 18px;
        text-align: center;
        color: #666;
        margin-bottom: 30px;
    }
    .stChatMessage {
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)

# PDFèª­ã¿è¾¼ã¿é–¢æ•°(è¤‡æ•°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå¯¾å¿œ)
@st.cache_data
def load_pdf(file_path="faq.pdf"):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º(è¤‡æ•°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå¯¾å¿œ)"""

    # æ–¹æ³•1: PyMuPDF(æœ€å¼·)
    if HAS_PYMUPDF:
        try:
            doc = fitz.open(file_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            if text and text.count('ï¿½') < 10:  # æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯
                st.success("âœ… PyMuPDF ã§èª­ã¿è¾¼ã¿æˆåŠŸ")
                return text
        except Exception as e:
            st.warning(f"PyMuPDFèª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}")
    else:
        st.info("ğŸ’¡ PyMuPDFæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install PyMuPDF")

    # æ–¹æ³•2: pdfplumber(æ—¥æœ¬èªã«å¼·ã„)
    if HAS_PDFPLUMBER:
        try:
            with pdfplumber.open(file_path) as pdf:
                text = ""
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"

            if text and text.count('ï¿½') < 10:  # æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯
                st.success("âœ… pdfplumber ã§èª­ã¿è¾¼ã¿æˆåŠŸ")
                return text
            else:
                st.warning("âš ï¸ pdfplumberã§æ–‡å­—åŒ–ã‘ã‚’æ¤œå‡º")
        except Exception as e:
            st.warning(f"pdfplumberèª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}")
    else:
        st.info("ğŸ’¡ pdfplumberæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install pdfplumber")

    # æ–¹æ³•3: PyPDF2(ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
    try:
        with open(file_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()

        if text and text.count('ï¿½') < 20:  # PyPDF2ã¯æ–‡å­—åŒ–ã‘ã—ã‚„ã™ã„ã®ã§ç·©ã„åŸºæº–
            st.warning("âš ï¸ PyPDF2ã§èª­ã¿è¾¼ã¿(æ–‡å­—åŒ–ã‘ã®å¯èƒ½æ€§ã‚ã‚Š)")
            return text
    except FileNotFoundError:
        st.error(f"âŒ {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚faq.pdfã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return ""
    except Exception as e:
        st.error(f"âŒ PyPDF2èª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}")

    # å…¨ã¦å¤±æ•—
    st.error("âŒ å…¨ã¦ã®æ–¹æ³•ã§PDFèª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    st.info("""
    ğŸ’¡ è§£æ±ºç­–:
    1. pip install PyMuPDF pdfplumber
    2. PDFã‚’ä½œã‚Šç›´ã™(Word â†’ PDF)
    3. ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ä½œæˆ
    """)
    return ""

# ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿(æ–‡å­—åŒ–ã‘å¯¾ç­–ã®ä»£æ›¿æ¡ˆ)
@st.cache_data
def load_txt_fallback(file_path="faq.txt"):
    """æ–‡å­—åŒ–ã‘å¯¾ç­–: ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

# FAQèª­ã¿è¾¼ã¿ãƒ»ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
@st.cache_data
def load_faq():
    """FAQèª­ã¿è¾¼ã¿(PDFâ†’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®é †ã§è©¦è¡Œ)"""
    # ã¾ãšPDFã‚’è©¦ã™
    content = load_pdf("faq.pdf")

    # PDFãŒèª­ã‚ãªã‹ã£ãŸã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã™
    if not content:
        content = load_txt_fallback("faq.txt")
        if content:
            st.info("ğŸ“ faq.txtã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    else:
        st.success("ğŸ“„ faq.pdfã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    if not content:
        st.error("âŒ faq.pdf ã¾ãŸã¯ faq.txt ã‚’é…ç½®ã—ã¦ãã ã•ã„")
        return []

    # Q&Aå˜ä½ã§åˆ†å‰²
    chunks = []
    lines = content.split("\n")
    current_chunk = ""

    for line in lines:
        if line.startswith("Q") and current_chunk:
            # æ–°ã—ã„QãŒå§‹ã¾ã£ãŸã‚‰ã€å‰ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
            chunks.append(current_chunk.strip())
            current_chunk = line + "\n"
        else:
            current_chunk += line + "\n"

    # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
    if current_chunk:
        chunks.append(current_chunk.strip())

    # ç©ºã®ãƒãƒ£ãƒ³ã‚¯ã‚’é™¤å¤–
    chunks = [c for c in chunks if c and len(c) > 20]

    # é•·ã™ãã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†å‰²(1ãƒãƒ£ãƒ³ã‚¯æœ€å¤§1500æ–‡å­—)
    final_chunks = []
    for chunk in chunks:
        if len(chunk) > 1500:
            # 1500æ–‡å­—ã”ã¨ã«åˆ†å‰²
            for i in range(0, len(chunk), 1500):
                final_chunks.append(chunk[i:i+1500])
        else:
            final_chunks.append(chunk)

    return final_chunks

# Embeddingå–å¾—(ãƒãƒƒãƒå‡¦ç†å¯¾å¿œ)
@st.cache_data
def get_embeddings(texts):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã‚’Embeddingã«å¤‰æ›(ãƒãƒƒãƒå‡¦ç†)"""
    if not texts:
        return []

    all_embeddings = []
    batch_size = 50  # ä¸€åº¦ã«å‡¦ç†ã™ã‚‹æ•°(ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾ç­–)

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒƒãƒã«åˆ†å‰²ã—ã¦å‡¦ç†
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]

        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=batch
        )

        batch_embeddings = [item.embedding for item in response.data]
        all_embeddings.extend(batch_embeddings)

    return all_embeddings

# ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
def cosine_similarity(vec1, vec2):
    """2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# é–¢é€£ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢
def search_relevant_chunks(query, chunks, embeddings, top_k=3):
    """è³ªå•ã«æœ€ã‚‚é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢"""
    if not chunks or not embeddings:
        return [], []

    # è³ªå•ã‚’EmbeddingåŒ–
    query_embedding = get_embeddings([query])[0]

    # å„ãƒãƒ£ãƒ³ã‚¯ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    similarities = [
        cosine_similarity(query_embedding, emb)
        for emb in embeddings
    ]

    # é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
    top_indices = np.argsort(similarities)[-top_k:][::-1]

    relevant_chunks = [chunks[i] for i in top_indices]
    scores = [similarities[i] for i in top_indices]

    return relevant_chunks, scores

# RAGå›ç­”ç”Ÿæˆ
def generate_rag_response(query, relevant_chunks):
    """é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å›ç­”ç”Ÿæˆ"""

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
    context = "\n\n".join(relevant_chunks)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    prompt = f"""ã‚ãªãŸã¯ã‚¢ãƒ³ãƒˆãƒ‹ã‚ªçŒªæœ¨ã«ã¤ã„ã¦è©³ã—ã„å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã‚’ã‚‚ã¨ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€å‚è€ƒæƒ…å ±ã€‘
{context}

ã€é‡è¦ãªæŒ‡ç¤ºã€‘
- å‚è€ƒæƒ…å ±ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã‚’ã‚‚ã¨ã«å›ç­”ã—ã¦ãã ã•ã„
- å‚è€ƒæƒ…å ±ã«ç„¡ã„å†…å®¹ã¯æ¨æ¸¬ã›ãšã€ã€Œå‚è€ƒæƒ…å ±ã«ã¯è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ä¼ãˆã¦ãã ã•ã„
- å›ç­”ã¯ä¸å¯§ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§
- å¿…è¦ã«å¿œã˜ã¦ã€çŒªæœ¨ã®åè¨€ã‚„ç²¾ç¥ã‚’äº¤ãˆã¦å›ç­”ã—ã¦ãã ã•ã„

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{query}"""

    # ChatGPT APIã§å›ç­”ç”Ÿæˆ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯ã‚¢ãƒ³ãƒˆãƒ‹ã‚ªçŒªæœ¨ã«ã¤ã„ã¦ã®è³ªå•ã«ç­”ãˆã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=1000
    )

    return response.choices[0].message.content

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

if "faq_chunks" not in st.session_state:
    with st.spinner("ğŸ“š FAQã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        st.session_state.faq_chunks = load_faq()

        if not st.session_state.faq_chunks:
            st.error("âš ï¸ FAQã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.info("ğŸ’¡ faq.pdf ã¾ãŸã¯ faq.txt ã‚’é…ç½®ã—ã¦ãã ã•ã„")
            st.stop()

if "faq_embeddings" not in st.session_state:
    with st.spinner("ğŸ” FAQã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­..."):
        st.session_state.faq_embeddings = get_embeddings(st.session_state.faq_chunks)

# UIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
col1, col2 = st.columns([3, 1])

with col1:
    st.markdown('<div class="main-title">ğŸ’ª ã‚¢ãƒ³ãƒˆãƒ‹ã‚ªçŒªæœ¨ FAQãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-title">å…ƒæ°—ã§ã™ã‹ã€œ! çŒªæœ¨ã«ã¤ã„ã¦ä½•ã§ã‚‚èã„ã¦ãã ã•ã„!</div>', unsafe_allow_html=True)

with col2:
    st.metric("FAQä»¶æ•°", len(st.session_state.faq_chunks))

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ RAGè¨­å®š")

    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªçŠ¶æ³è¡¨ç¤º
    st.markdown("### ğŸ“š PDFèª­ã¿è¾¼ã¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
    if HAS_PYMUPDF:
        st.success("âœ… PyMuPDF (æ¨å¥¨)")
    else:
        st.error("âŒ PyMuPDF æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

    if HAS_PDFPLUMBER:
        st.success("âœ… pdfplumber")
    else:
        st.error("âŒ pdfplumber æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

    st.success("âœ… PyPDF2 (æ¨™æº–)")

    if not HAS_PYMUPDF and not HAS_PDFPLUMBER:
        st.warning("âš ï¸ æ—¥æœ¬èªPDFå¯¾å¿œãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚ã‚Šã¾ã›ã‚“")
        st.code("pip install PyMuPDF pdfplumber")

    st.markdown("---")

    top_k = st.slider(
        "å‚è€ƒã«ã™ã‚‹FAQæ•°",
        min_value=1,
        max_value=5,
        value=3,
        help="è³ªå•ã«é–¢é€£ã™ã‚‹FAQã‚’ã„ãã¤å‚è€ƒã«ã™ã‚‹ã‹é¸æŠ"
    )

    show_context = st.checkbox(
        "å‚è€ƒã«ã—ãŸFAQã‚’è¡¨ç¤º",
        value=True,
        help="AIãŒã©ã®FAQã‚’å‚è€ƒã«ã—ãŸã‹è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™"
    )

    st.markdown("---")
    st.markdown("### ğŸ’¡ RAGã¨ã¯?")
    st.markdown("""
    **Retrieval-Augmented Generation**

    1. è³ªå•ã‚’å—ã‘å–ã‚‹
    2. PDFã‹ã‚‰é–¢é€£FAQã‚’æ¤œç´¢
    3. æ¤œç´¢çµæœã‚’å…ƒã«å›ç­”ç”Ÿæˆ

    â†’ æ­£ç¢ºã§æ ¹æ‹ ã®ã‚ã‚‹å›ç­”!
    """)

    st.markdown("---")
    st.markdown("### ğŸ” é¡ä¼¼åº¦ã®ä»•çµ„ã¿")
    st.markdown(f"""
    **ç¾åœ¨ã®è¨­å®š**: ä¸Šä½{top_k}å€‹ã®FAQã‚’å‚è€ƒ

    **è¨ˆç®—æ–¹æ³•**:
    1. è³ªå•ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–(æ•°å€¤åŒ–)
    2. å„FAQã‚‚ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¸ˆã¿
    3. ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æ¯”è¼ƒ
    4. é¡ä¼¼åº¦ãŒé«˜ã„é †ã«é¸æŠ

    **é¡ä¼¼åº¦ã®è¦‹æ–¹**:
    - 1.0ã«è¿‘ã„ = ã¨ã¦ã‚‚é–¢é€£
    - 0.5ç¨‹åº¦ = ã‚ã‚‹ç¨‹åº¦é–¢é€£
    - 0.2ä»¥ä¸‹ = ã‚ã¾ã‚Šé–¢é€£ãªã—
    """)

    st.markdown("---")
    st.markdown("### ğŸš€ ä½¿ã„æ–¹")
    st.markdown("""
    - çŒªæœ¨ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„
    - ä¾‹:ã€Œå¿…æ®ºæŠ€ã¯?ã€
    - ä¾‹:ã€Œã‚¢ãƒªæˆ¦ã«ã¤ã„ã¦ã€
    - ä¾‹:ã€Œåè¨€ã‚’æ•™ãˆã¦ã€
    """)

    if st.button("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.rerun()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º(ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ‰åŠ¹ã«ã—ã¦ã„ã‚‹å ´åˆ)
        if show_context and "context" in message:
            with st.expander(f"ğŸ“„ å‚è€ƒã«ã—ãŸ{len(message['context'])}ä»¶ã®FAQ"):
                for i, chunk in enumerate(message["context"], 1):
                    score = message['scores'][i-1]

                    # é¡ä¼¼åº¦ã«å¿œã˜ã¦è‰²ã‚’å¤‰ãˆã‚‹
                    if score > 0.8:
                        color = "ğŸŸ¢"
                        level = "ã¨ã¦ã‚‚é–¢é€£"
                    elif score > 0.5:
                        color = "ğŸŸ¡"
                        level = "é–¢é€£"
                    elif score > 0.3:
                        color = "ğŸŸ "
                        level = "ã‚„ã‚„é–¢é€£"
                    else:
                        color = "ğŸ”´"
                        level = "ã‚ã¾ã‚Šé–¢é€£ãªã—"

                    st.markdown(f"**{color} FAQ{i}** (é¡ä¼¼åº¦: {score:.2f} - {level})")

                    # æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯
                    if chunk.count('ï¿½') > 5:
                        st.warning("âš ï¸ ã“ã®å†…å®¹ã¯æ–‡å­—åŒ–ã‘ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                        st.text("æ–‡å­—åŒ–ã‘å¯¾ç­–: faq.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™")
                    else:
                        # æ­£å¸¸ãªå ´åˆã¯å†…å®¹ã‚’è¡¨ç¤º
                        display_text = chunk[:400] + "..." if len(chunk) > 400 else chunk
                        st.text(display_text)

                    st.markdown("---")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("çŒªæœ¨ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ (ä¾‹: å¿…æ®ºæŠ€ã¯?)"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIå¿œç­”ç”Ÿæˆ
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ä¸­..."):
            # é–¢é€£ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢
            relevant_chunks, scores = search_relevant_chunks(
                prompt,
                st.session_state.faq_chunks,
                st.session_state.faq_embeddings,
                top_k=top_k
            )

        with st.spinner("ğŸ’¬ å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            # RAGå›ç­”ç”Ÿæˆ
            response = generate_rag_response(prompt, relevant_chunks)

        st.markdown(response)

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
        if show_context:
            with st.expander(f"ğŸ“„ å‚è€ƒã«ã—ãŸ{len(relevant_chunks)}ä»¶ã®FAQ"):
                for i, (chunk, score) in enumerate(zip(relevant_chunks, scores), 1):
                    # é¡ä¼¼åº¦ã«å¿œã˜ã¦è‰²ã‚’å¤‰ãˆã‚‹
                    if score > 0.8:
                        color = "ğŸŸ¢"
                        level = "ã¨ã¦ã‚‚é–¢é€£"
                    elif score > 0.5:
                        color = "ğŸŸ¡"
                        level = "é–¢é€£"
                    elif score > 0.3:
                        color = "ğŸŸ "
                        level = "ã‚„ã‚„é–¢é€£"
                    else:
                        color = "ğŸ”´"
                        level = "ã‚ã¾ã‚Šé–¢é€£ãªã—"

                    st.markdown(f"**{color} FAQ{i}** (é¡ä¼¼åº¦: {score:.2f} - {level})")

                    # æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯
                    if chunk.count('ï¿½') > 5:
                        st.warning("âš ï¸ ã“ã®å†…å®¹ã¯æ–‡å­—åŒ–ã‘ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                        st.text("æ–‡å­—åŒ–ã‘å¯¾ç­–: faq.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™")
                    else:
                        # æ­£å¸¸ãªå ´åˆã¯å†…å®¹ã‚’è¡¨ç¤º
                        display_text = chunk[:400] + "..." if len(chunk) > 400 else chunk
                        st.text(display_text)

                    st.markdown("---")

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
    st.session_state.messages.append({
        "role": "assistant",
        "content": response,
        "context": relevant_chunks,
        "scores": scores
    })

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <strong>ç‡ƒãˆã‚‹é—˜é­‚ ğŸ”¥</strong> | ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯RAGæŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™<br>
    <small>ã€Œå…ƒæ°—ãŒã‚ã‚Œã°ä½•ã§ã‚‚ã§ãã‚‹!ã€ - ã‚¢ãƒ³ãƒˆãƒ‹ã‚ªçŒªæœ¨</small>
</div>
""", unsafe_allow_html=True)